---
layout:     post
title:      "Existentialist risk from advanced AI"
baselink:   /existrisk
permalink:  /existrisk
date:       2025-10-10
author:     Gavin
img:        /img/

visible:    1
published:  false
quality:    5

summary:    
warnings: 	
confidence: 
importance: 8
wordcount:  
categories: 
where:      "Sevenoaks"
---

What people find meaningful is pretty radically contingent on cultural vagaries.

Hunting
Tending the Land -> HGs didn't. And now half of people don't spend any time there. 90% don't till
Parenthood


https://www.hup.harvard.edu/books/9780674984240

Danaher breaking down the difficult and disreputable concept of “authenticity” a bit:


Gavin: 
Say you’re alive. Say you’re not immiserated. Say you’re allowed to decide things for yourself. You’re not overtly domesticated or otherwise simplified. Say even that there’s an honest-to-god benevolent overlord. 

But this last one means that you’re not capable of being the best at anything, of really counterfactually changing anything, making anything new, of understanding how the new social world works, of resisting systematic hypernudging and ideological shaping.

OK, sans overlord I’ve just described the present situation for most people. But now say that this relative lack applies to every human to an unprecedented degree. 

Is this undignified? Can dignity adapt itself to new realities? We are going to select for people who are fine with this. Do “we” lose anything, in selecting out the other people?

How much value is lost in this? What fraction of value is in dignity?

I’m open to the above being confused in some way – e.g. maybe the description length of any interesting person’s art is too long for all such art to be counterfactually covered by like exhaustive enumeration; e.g. maybe AI’s predictive or elicited model of you will always be notably off and so you rolling out your project is in fact counterfactual.


(For illustration: Say you are a pioneering sort, and don’t like mere entertainment or dependence on AI or even just being constantly surveilled. So you go off to a new planet without AI and set about doing your things there. It seems like part of the value of doing this is in fact unattainable while ASI exists, since it could have done it much better; maybe it could have predicted or elicited from you much of the project’s detail.

Even if they’re not looking, they could.)


(More fiction:

“So what," the Chelgrian asked, "is the point of me or anybody else writing a symphony, or anything else?"
The [AI] raised its brows in surprise. "Well, for one thing, you do it, it's you who gets the feeling of achievement."
"Ignoring the subjective. What would be the point for those listening to it?"
"They'd know it was one of their own species, not a Mind, who created it."
"Ignoring that, too; suppose they weren't told it was by an AI, or didn't care."
"If they hadn't been told then the comparison isn't complete; information is being concealed. If they don't care, then they're unlike any group of humans I've ever encountered."
"But if you can—"
"Ziller, are you concerned that Minds—AIs, if you like—can create, or even just appear to create, original works of art?"
"Frankly, when they're the sort of original works of art that I create, yes."
"Ziller, it doesn't matter. You have to think like a mountain climber."
"Oh, do I?"
"Yes. Some people take days, sweat buckets, endure pain and cold and risk injury and—in some cases—permanent death to achieve the summit of a mountain only to discover there a party of their peers freshly arrived by aircraft and enjoying a light picnic."
"If I was one of those climbers I'd be pretty damned annoyed."
"Well, it is considered rather impolite to land an aircraft on a summit which people are at that moment struggling up to the hard way, but it can and does happen. Good manners indicate that the picnic ought to be shared and that those who arrived by aircraft express awe and respect for the accomplishment of the climbers.
"The point, of course, is that the people who spent days and sweated buckets could also have taken an aircraft to the summit if all they'd wanted was to absorb the view. It is the struggle that they crave. The sense of achievement is produced by the route to and from the peak, not by the peak itself. It is just the fold between the pages." The avatar hesitated. It put its head a little to one side and narrowed its eyes. "How far do I have to take this analogy, Cr. Ziller?”
)

Now trying to think of answers instead of hugging the problem:

vs Severance risk. Seems hard.
vs Attention risk. Not hard to get rid of a current-style attention economy, but probably quite hard to stop selection for memetically fit ideas / stop all persuasion.
vs Opacity risk. Intense limits to design space. Intentionally simple political system, maybe even economy. Maximise the understanding of the stupidest mind in your society.
vs Autonomy risk
vs Agency risk



Now without AI

Does time alone cause an exis risk?

Weinberg:
As is often noted, in a thousand years it will (probably) be as though you had never lived. Everything you strived for will have crumbled to dust. Weinberg doesn't argue that this renders our efforts entirely meaningless -- but it does deprive them of a meaning they would have had, if they had endured. We ought to admit, she says, that this is disheartening, rather than brushing it off with a breezy recommendation to "live in the moment".

Atelic goods are complete in the moment: strolling through the woods, enjoying a sunset, licking an ice cream cone. Contrast these with telic goods, which aim toward a goal: walking to the store, taking the perfect sunset photo, finishing the cone.


Gavin: This account totally ignores the longtermist assumption of ripple effects, focussing entirely on subjective meaning, named legacy, permanent evidence, etc. It’s thus maybe contemptible – but it seems like a lot of current people run on this axiology, so it might persist and might cause suffering. 

- MM: any straightforward ways by which to increase the legibility and/or duration of partcular impacts throughout time? e.g. get everyone to carve their sigil into their own Voyager probe; [though of course doesn’t extend indefinitely still].  
